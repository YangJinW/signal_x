{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "2. was-> mel Spectrogram 변환"
      ],
      "metadata": {
        "id": "YrBlWEmgpy3v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "wav데이터를 fold1부터 fold10까지 순차적으로 이미지 변환 시켜주는 코드"
      ],
      "metadata": {
        "id": "YgIAm9pvSmcy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# ✅ 설정: 처리할 폴더 번호만 수정하세요 (1~10)\n",
        "target_fold = 10  # <- 여기만 매번 바꿔서 실행\n",
        "\n",
        "# 경로 설정\n",
        "metadata_path = \"/content/drive/MyDrive/UrbanSound8K/metadata/UrbanSound8K.csv\"\n",
        "audio_base_path = \"/content/drive/MyDrive/UrbanSound8K/audio\"\n",
        "save_base_path = \"/content/drive/MyDrive/UrbanSound8K/images\"\n",
        "\n",
        "# 메타데이터 불러오기\n",
        "df = pd.read_csv(metadata_path)\n",
        "\n",
        "# 해당 fold 데이터만 필터링\n",
        "fold_df = df[df[\"fold\"] == target_fold]\n",
        "\n",
        "# 저장 폴더 준비\n",
        "save_folder = os.path.join(save_base_path, f\"fold{target_fold}\")\n",
        "os.makedirs(save_folder, exist_ok=True)\n",
        "\n",
        "# Mel 이미지 생성 루프\n",
        "for idx, row in fold_df.iterrows():\n",
        "    file_name = row['slice_file_name']\n",
        "    audio_path = os.path.join(audio_base_path, f\"fold{target_fold}\", file_name)\n",
        "    save_path = os.path.join(save_folder, file_name.replace('.wav', '.png'))\n",
        "\n",
        "    try:\n",
        "        y, sr = librosa.load(audio_path, sr=None)\n",
        "        S = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128)\n",
        "        S_DB = librosa.power_to_db(S, ref=np.max)\n",
        "\n",
        "        plt.figure(figsize=(3, 3))\n",
        "        librosa.display.specshow(S_DB, sr=sr, x_axis=None, y_axis=None)\n",
        "        plt.axis(\"off\")\n",
        "        plt.savefig(save_path, bbox_inches='tight', pad_inches=0)\n",
        "        plt.close()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ 오류 발생: {file_name} - {e}\")\n"
      ],
      "metadata": {
        "id": "vleIjpXoSlQQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.클래스 라벨링 필터링**"
      ],
      "metadata": {
        "id": "0yuxsN3VplXV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "클래스 3개 이상 만들기 사이렌 경적 드릴링"
      ],
      "metadata": {
        "id": "mRfyR3fDEzAI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/UrbanSound8K/metadata/UrbanSound8K.csv\")\n",
        "\n",
        "siren_df = df[df['class']=='siren']\n",
        "non_siren_df = df[df['class'] !='siren']\n",
        "final_df = pd.concat([siren_df, non_siren_df.sample(n=len(siren_df))])"
      ],
      "metadata": {
        "id": "5-TMnuZedl_t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(r\"/content/drive/MyDrive/UrbanSound8K/metadata/UrbanSound8K.csv\")\n",
        "\n",
        "# 사이렌 classID == 10\n",
        "siren_df = df[df['classID'] == 10].copy()\n",
        "siren_df['binary_label'] = 1\n",
        "\n",
        "non_siren_df = df[df['classID'] != 10].copy()\n",
        "non_siren_df['binary_label'] = 0\n",
        "\n",
        "# 이진 분류용 데이터프레임\n",
        "final_df = pd.concat([siren_df, non_siren_df], ignore_index=True)\n"
      ],
      "metadata": {
        "id": "ttgmnIrRv_ej"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(final_df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xf429HHDwTWs",
        "outputId": "a56bf9da-ec63-4a47-f6c7-b4c7756e4061"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      slice_file_name    fsID  start        end  salience  fold  classID  \\\n",
            "0    100032-3-0-0.wav  100032    0.0   0.317551         1     5        3   \n",
            "1  100263-2-0-117.wav  100263   58.5  62.500000         1     5        2   \n",
            "2  100263-2-0-121.wav  100263   60.5  64.500000         1     5        2   \n",
            "3  100263-2-0-126.wav  100263   63.0  67.000000         1     5        2   \n",
            "4  100263-2-0-137.wav  100263   68.5  72.500000         1     5        2   \n",
            "\n",
            "              class  binary_label  \n",
            "0          dog_bark             0  \n",
            "1  children_playing             0  \n",
            "2  children_playing             0  \n",
            "3  children_playing             0  \n",
            "4  children_playing             0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(final_df['binary_label'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XfFhfvPqxT4I",
        "outputId": "4917afe7-dca3-4486-ed8f-2fa288ecd355"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "binary_label\n",
            "0    8732\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(final_df[final_df['binary_label'] == 1].head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZfIo_XojxczA",
        "outputId": "1170e23c-9ae7-4be6-e149-cacd0fa61f83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Empty DataFrame\n",
            "Columns: [slice_file_name, fsID, start, end, salience, fold, classID, class, binary_label]\n",
            "Index: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.columns)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Sdlu2hUyWUk",
        "outputId": "b7e92cc4-ef1c-496f-9470-b1c9c49c3dd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['slice_file_name', 'fsID', 'start', 'end', 'salience', 'fold',\n",
            "       'classID', 'class'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/UrbanSound8K/metadata/UrbanSound8K.csv\")\n",
        "print(df['class'].unique())  # 클래스를 먼저 확인해보기\n",
        "\n",
        "# classID 또는 class 기준으로 필터링\n",
        "siren_df = df[df['class'] == 'siren'].copy()\n",
        "siren_df['binary_label'] = 1\n",
        "\n",
        "non_siren_df = df[df['class'] != 'siren'].copy()\n",
        "non_siren_df['binary_label'] = 0\n",
        "\n",
        "final_df = pd.concat([siren_df, non_siren_df], ignore_index=True)\n",
        "print(final_df['binary_label'].value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_kGtv8OYzkUp",
        "outputId": "ebc4ca5a-8947-4890-8d7a-70a8f7e21a3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['dog_bark' 'children_playing' 'car_horn' 'air_conditioner' 'street_music'\n",
            " 'gun_shot' 'siren' 'engine_idling' 'jackhammer' 'drilling']\n",
            "binary_label\n",
            "0    7803\n",
            "1     929\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.PyTorch Dataset 구성"
      ],
      "metadata": {
        "id": "jIm0fxYjr0bb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class SpectrogramDataset(Dataset):\n",
        "    def __init__(self, dataframe, base_path, transform=None):\n",
        "        self.df = dataframe.reset_index(drop=True)\n",
        "        self.base_path = base_path\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        filepath = f\"{self.base_path}/fold\"\n",
        "        y,sr = librosa.load(filepath, sr=None)\n",
        "        mel = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128)\n",
        "        mel_db = librosa.power_to_db(mel, ref=np.max)\n",
        "        mel_tensor = torch.tensor(mel_db).unsqueeze(0).float()\n",
        "        label = int (row.classID == 10)\n",
        "        return mel_tensor, label"
      ],
      "metadata": {
        "id": "jpegKEPcpkm-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "import torch\n",
        "import librosa\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "class SpectrogramDataset(Dataset):\n",
        "    def __init__(self, dataframe, base_path, transform=None):\n",
        "        self.df = dataframe.reset_index(drop=True)\n",
        "        self.base_path = base_path\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        fold = f\"fold{row['fold']}\"\n",
        "        filename = row['slice_file_name']\n",
        "        filepath = os.path.join(self.base_path, fold, filename)\n",
        "\n",
        "        y, sr = librosa.load(filepath, sr=None)\n",
        "        mel = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128)\n",
        "        mel_db = librosa.power_to_db(mel, ref=np.max)\n",
        "        mel_tensor = torch.tensor(mel_db).unsqueeze(0).float()  # shape: (1, 128, time)\n",
        "\n",
        "        label = int(row['classID'] == 10)  # 사이렌이면 1, 아니면 0\n",
        "\n",
        "        return mel_tensor, label\n"
      ],
      "metadata": {
        "id": "8oAEZgyQ1xGp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5.모델 학습"
      ],
      "metadata": {
        "id": "UhzWfiFCsv2P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "\n",
        "model = models.resnet18(pretrained=False)\n",
        "model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "model.fc = nn.Linear(model.fc.in_features, 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OaFFgd1usveg",
        "outputId": "78fd71c3-279d-4e30-f2c8-0cb0bbd886bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ftAb50X-29On",
        "outputId": "4916bb6b-c3a8-4000-d704-a325a606190c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResNet(\n",
            "  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=512, out_features=1, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. 모델 저장"
      ],
      "metadata": {
        "id": "m8De5YRptS-b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"/content/drive/MyDrive/resnet_siren_classifier.pth\")"
      ],
      "metadata": {
        "id": "9-MGSvTWtSyk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "-sBtU7-7sB41"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 같은 모델 구조로 불러올 준비\n",
        "model = models.resnet18(weights=None)\n",
        "model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "model.fc = nn.Linear(model.fc.in_features, 1)\n",
        "\n",
        "# 저장된 가중치 불러오기\n",
        "model.load_state_dict(torch.load(\"resnet_siren_classifier.pth\"))\n",
        "model.eval()  # 추론 모드 전환\n"
      ],
      "metadata": {
        "id": "2KJXqjSlr0gl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# 저장된 모델 파라미터 로드\n",
        "state_dict = torch.load(\"/content/drive/MyDrive/resnet_siren_classifier.pth\")\n",
        "\n",
        "# 키 목록 확인 (모델 각 층의 이름)\n",
        "print(state_dict.keys())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XNCxkHQrsIrr",
        "outputId": "9582abb2-4feb-4c05-9491-70ed010a29c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.downsample.0.weight', 'layer2.0.downsample.1.weight', 'layer2.0.downsample.1.bias', 'layer2.0.downsample.1.running_mean', 'layer2.0.downsample.1.running_var', 'layer2.0.downsample.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.downsample.0.weight', 'layer3.0.downsample.1.weight', 'layer3.0.downsample.1.bias', 'layer3.0.downsample.1.running_mean', 'layer3.0.downsample.1.running_var', 'layer3.0.downsample.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.downsample.0.weight', 'layer4.0.downsample.1.weight', 'layer4.0.downsample.1.bias', 'layer4.0.downsample.1.running_mean', 'layer4.0.downsample.1.running_var', 'layer4.0.downsample.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'fc.weight', 'fc.bias'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(state_dict['fc.weight'])  # 최종 분류기 가중치\n"
      ],
      "metadata": {
        "id": "MOXKwqlAtIox",
        "outputId": "c75a3b77-ca7c-45eb-8ea9-3104066540c6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.0028,  0.0218,  0.0332, -0.0162,  0.0062,  0.0027, -0.0121,  0.0164,\n",
            "          0.0312, -0.0044, -0.0294,  0.0063, -0.0008,  0.0404,  0.0004, -0.0357,\n",
            "         -0.0439,  0.0331, -0.0352, -0.0056, -0.0091, -0.0038, -0.0125,  0.0002,\n",
            "          0.0160, -0.0128,  0.0275, -0.0016,  0.0201, -0.0388,  0.0268, -0.0404,\n",
            "         -0.0010, -0.0201, -0.0168,  0.0165, -0.0347,  0.0053, -0.0010, -0.0385,\n",
            "          0.0160, -0.0142,  0.0280, -0.0087,  0.0254,  0.0340, -0.0193, -0.0432,\n",
            "         -0.0042,  0.0002, -0.0416,  0.0134, -0.0390, -0.0201,  0.0233, -0.0146,\n",
            "         -0.0008, -0.0182, -0.0212,  0.0120, -0.0207, -0.0081, -0.0253, -0.0344,\n",
            "         -0.0200, -0.0283, -0.0301,  0.0420, -0.0233,  0.0065, -0.0369, -0.0151,\n",
            "          0.0218,  0.0377, -0.0326, -0.0004,  0.0204, -0.0328,  0.0163,  0.0162,\n",
            "          0.0005,  0.0071,  0.0135,  0.0197,  0.0045,  0.0265, -0.0280,  0.0141,\n",
            "         -0.0189,  0.0083, -0.0331,  0.0095, -0.0155, -0.0144, -0.0187,  0.0333,\n",
            "          0.0175,  0.0189,  0.0151, -0.0415,  0.0071,  0.0086,  0.0134, -0.0171,\n",
            "          0.0002, -0.0151, -0.0246,  0.0286, -0.0093,  0.0047, -0.0438, -0.0164,\n",
            "          0.0297,  0.0073,  0.0069, -0.0302, -0.0440,  0.0263, -0.0302, -0.0192,\n",
            "         -0.0125, -0.0254, -0.0147, -0.0353,  0.0007, -0.0343, -0.0124,  0.0434,\n",
            "         -0.0295, -0.0300,  0.0200,  0.0019, -0.0237, -0.0037, -0.0065, -0.0341,\n",
            "          0.0281,  0.0406, -0.0431, -0.0059, -0.0158, -0.0143, -0.0397, -0.0384,\n",
            "          0.0413, -0.0273,  0.0170, -0.0285, -0.0189, -0.0385, -0.0164, -0.0208,\n",
            "         -0.0020,  0.0315, -0.0051,  0.0293,  0.0237,  0.0044,  0.0009, -0.0302,\n",
            "         -0.0098,  0.0198, -0.0404,  0.0302,  0.0426,  0.0415,  0.0317, -0.0022,\n",
            "          0.0048,  0.0282, -0.0144,  0.0351, -0.0232, -0.0366,  0.0053,  0.0238,\n",
            "          0.0016,  0.0152, -0.0177, -0.0034, -0.0004, -0.0120, -0.0284,  0.0130,\n",
            "          0.0440,  0.0261,  0.0026, -0.0323, -0.0071, -0.0432,  0.0429, -0.0391,\n",
            "         -0.0198,  0.0156, -0.0263, -0.0095, -0.0377,  0.0366, -0.0108, -0.0294,\n",
            "          0.0182, -0.0314, -0.0087, -0.0390, -0.0113, -0.0050, -0.0178,  0.0387,\n",
            "         -0.0217, -0.0227, -0.0343,  0.0326,  0.0250, -0.0044,  0.0289, -0.0409,\n",
            "          0.0104,  0.0183, -0.0407, -0.0205,  0.0185,  0.0358, -0.0023,  0.0407,\n",
            "          0.0348, -0.0030, -0.0032,  0.0145, -0.0139,  0.0060, -0.0082, -0.0228,\n",
            "         -0.0358, -0.0035, -0.0308,  0.0321,  0.0329,  0.0110,  0.0371, -0.0410,\n",
            "          0.0192, -0.0079, -0.0029, -0.0372, -0.0357,  0.0034, -0.0232,  0.0042,\n",
            "         -0.0019,  0.0402,  0.0002, -0.0426,  0.0169,  0.0341, -0.0222,  0.0394,\n",
            "          0.0323, -0.0334, -0.0197, -0.0075, -0.0177,  0.0139,  0.0205, -0.0156,\n",
            "         -0.0081, -0.0196,  0.0091,  0.0413, -0.0039, -0.0243, -0.0398,  0.0095,\n",
            "          0.0157,  0.0106,  0.0031,  0.0347, -0.0319, -0.0295,  0.0329,  0.0199,\n",
            "          0.0064,  0.0409,  0.0380,  0.0404,  0.0069, -0.0300,  0.0118,  0.0257,\n",
            "         -0.0137,  0.0187,  0.0322,  0.0403, -0.0288, -0.0138, -0.0222,  0.0400,\n",
            "          0.0116,  0.0417, -0.0383, -0.0191,  0.0066, -0.0422, -0.0093,  0.0171,\n",
            "         -0.0156,  0.0318, -0.0303,  0.0171, -0.0159,  0.0110,  0.0280, -0.0292,\n",
            "         -0.0422, -0.0073,  0.0078,  0.0051, -0.0318,  0.0326,  0.0167,  0.0285,\n",
            "          0.0304,  0.0063,  0.0279,  0.0062, -0.0010, -0.0412,  0.0122,  0.0405,\n",
            "         -0.0433, -0.0009, -0.0288,  0.0280,  0.0318, -0.0328,  0.0350,  0.0373,\n",
            "         -0.0195, -0.0139, -0.0144, -0.0344,  0.0360, -0.0159,  0.0098,  0.0234,\n",
            "         -0.0031, -0.0207,  0.0088, -0.0317, -0.0244, -0.0307,  0.0286,  0.0381,\n",
            "         -0.0207,  0.0171,  0.0320, -0.0217, -0.0133,  0.0317, -0.0197, -0.0064,\n",
            "          0.0104,  0.0015, -0.0393,  0.0310,  0.0113,  0.0224,  0.0209, -0.0393,\n",
            "         -0.0270, -0.0004,  0.0136, -0.0361, -0.0440,  0.0007, -0.0326,  0.0215,\n",
            "          0.0364, -0.0138,  0.0028, -0.0329,  0.0367,  0.0027,  0.0347,  0.0072,\n",
            "          0.0270,  0.0381, -0.0291,  0.0207,  0.0368,  0.0345, -0.0147,  0.0059,\n",
            "         -0.0438, -0.0230,  0.0148,  0.0324,  0.0127,  0.0270,  0.0304,  0.0169,\n",
            "         -0.0062, -0.0057,  0.0375, -0.0326,  0.0332,  0.0035, -0.0030, -0.0400,\n",
            "          0.0094, -0.0353,  0.0322,  0.0223,  0.0111,  0.0435, -0.0098, -0.0144,\n",
            "          0.0045,  0.0030, -0.0201,  0.0067,  0.0209, -0.0067,  0.0431,  0.0229,\n",
            "         -0.0288,  0.0146, -0.0188, -0.0373,  0.0214, -0.0436,  0.0054, -0.0364,\n",
            "          0.0403, -0.0016,  0.0095,  0.0280,  0.0114, -0.0072,  0.0411,  0.0343,\n",
            "          0.0419,  0.0210,  0.0054,  0.0303, -0.0126,  0.0003,  0.0428, -0.0374,\n",
            "         -0.0377,  0.0270, -0.0176,  0.0397, -0.0146, -0.0398, -0.0173, -0.0010,\n",
            "         -0.0041,  0.0325,  0.0317,  0.0372, -0.0257,  0.0155,  0.0308, -0.0258,\n",
            "         -0.0208, -0.0009,  0.0377, -0.0209, -0.0397,  0.0115,  0.0247,  0.0018,\n",
            "          0.0138,  0.0067,  0.0216,  0.0407,  0.0151, -0.0226, -0.0283,  0.0196,\n",
            "         -0.0060, -0.0334, -0.0148,  0.0252,  0.0205, -0.0300,  0.0404,  0.0252,\n",
            "          0.0156, -0.0430,  0.0277, -0.0300,  0.0041,  0.0388,  0.0414, -0.0030,\n",
            "          0.0435,  0.0323,  0.0087,  0.0394,  0.0317,  0.0054, -0.0312, -0.0249,\n",
            "          0.0187, -0.0430, -0.0301, -0.0407,  0.0343, -0.0052, -0.0360,  0.0304]])\n"
          ]
        }
      ]
    }
  ]
}